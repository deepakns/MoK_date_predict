# Model Configuration
model:
  name: "MoK_CNN_04p2"
  architecture: "SpatialProcessor"  # Example architecture
  input_shape: [36, 1440, 481]  # 36 channels: 15 surface + 18 pressure + 1 land_sea_mask + 2 coords
  target: 1

# Training Configuration
training:
  epochs: 100 # batch size is set in data section
  learning_rate: 0.001
  optimizer: "adam"
  loss: "mse"
  random_seed: 42  # For reproducibility
  
  # Callbacks
  early_stopping:
    enabled: true
    patience: 10
    monitor: "val_loss"
  
  checkpoint:
    enabled: true
    save_best_only: true
    monitor: "val_loss"

# Data Configuration
data:
  # Path to ERA5 monthly NetCDF files
  data_dir: "/gdata2/ERA5/monthly"

  # Path to target CSV file (Year, DateRelJun01)
  target_file: "/home/deepakns/Work/data/MoKDates.csv"

  # Year specifications can be:
  # - Single years: 1962, 1965
  # - Ranges: "1950:1960" (inclusive, both start and end)
  # - Mix of both: ["1950:1960", 1962, "1964:2000"]
  train_years: ["1950:1960", "1966:1990", "1996:2005"]
  val_years: ["2011:2024"]
  test_years: ["1961:1965", "1991:1995"]

  # DataLoader settings
  batch_size: 10
  num_workers: 2

  # Dataset settings
  # Number of consecutive time steps to load per year (each year produces ONE sample)
  # For example, num_time_steps: 3 means each year will use the first 3 months (e.g., Feb, Mar, Apr)
  # as one sample with 3 time steps stacked as separate channels
  num_time_steps: 3
  pressure_levels: [0, 1]  # Indices of pressure levels to extract

  # Normalization strategy
  # 0: No normalization (raw data)
  # 1: Normalize using training data statistics (spatially-varying mean/std)
  # Future: Additional strategies can be added (e.g., 2: per-sample normalization, etc.)
  normalize_strategy: 1

  augmentation:
    enabled: true
    rotation_range: 15
    width_shift_range: 0.1
    height_shift_range: 0.1
    horizontal_flip: true

# Logging
logging:
  log_dir: "logs"
  tensorboard: true
  save_frequency: 1  # Save every N epochs
